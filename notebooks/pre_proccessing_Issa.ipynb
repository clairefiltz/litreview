{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18b8a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"spacy\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "import dask.bag as db\n",
    "from dask.bag import Item\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "docs = db.read_text('/Users/issa/code/clairefiltz/litreview/raw_data/arxiv-metadata-oai-snapshot.json').map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eead15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start prototyping with a subset of the data so it's easyer to handel:\n",
    "# This procedure was recommended in the ArXiv dataset itself\n",
    "\n",
    "get_latest_version = lambda x: x['versions'][-1]['created']\n",
    "\n",
    "\n",
    "# get only necessary fields of the metadata file\n",
    "trim = lambda x: {'id': x['id'],\n",
    "                  'authors': x['authors'],\n",
    "                  'title': x['title'],\n",
    "                  'doi': x['doi'],\n",
    "                  'category':x['categories'].split(' '),\n",
    "                  'abstract':x['abstract'],}\n",
    "# filter for papers published on or after 2019-01-01\n",
    "columns = ['id','category','abstract']\n",
    "docs_df = (docs.filter(lambda x: int(get_latest_version(x).split(' ')[3]) > 2018).map(trim).compute())\n",
    "\n",
    "# convert to pandas\n",
    "docs_df = pd.DataFrame(docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59c57b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541338, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a67668ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046.829548267441"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['abstract'].apply(len).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "931c7ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['abstract'].apply(len).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd50b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = docs_df.drop(docs_df[docs_df['abstract'].apply(len) < 1046].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcd7decc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265819, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7af08edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['abstract'].apply(len).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776cf7f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: joblib in /Users/issa/.pyenv/versions/3.8.12/envs/litreview/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2021.11.10-cp38-cp38-macosx_10_9_x86_64.whl (288 kB)\n",
      "     |████████████████████████████████| 288 kB 3.3 MB/s            \n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 13.3 MB/s            \n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.0.3 nltk-3.6.5 regex-2021.11.10 tqdm-4.62.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e37cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling a smaller subset of 1K\n",
    "docs_1k = docs_df.sample(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1b4c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for punctuation in string.punctuation: \n",
    "        text = text.replace(punctuation, ' ') \n",
    "    return text\n",
    "\n",
    "def lowercase(text): \n",
    "    lowercased = text.lower() \n",
    "    return lowercased\n",
    "\n",
    "def remove_numbers(text):\n",
    "    words_only = ''.join([i for i in text if not i.isdigit()])\n",
    "    return words_only\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokenized = word_tokenize(text)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    return without_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8655c276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>category</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178481</th>\n",
       "      <td>1911.02749</td>\n",
       "      <td>Tong Zhang and Fatih Porikli</td>\n",
       "      <td>Sparse Coding on Cascaded Residuals</td>\n",
       "      <td>None</td>\n",
       "      <td>[cs.CV, cs.LG, eess.IV]</td>\n",
       "      <td>This paper seeks to combine dictionary learn...</td>\n",
       "      <td>[paper, seeks, combine, dictionary, learning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331163</th>\n",
       "      <td>2009.12524</td>\n",
       "      <td>Zanyar Zohourianshahzadi (UCCS) and Jugal Kuma...</td>\n",
       "      <td>Neural Twins Talk</td>\n",
       "      <td>10.1109/HCCAI49649.2020.00009</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>Inspired by how the human brain employs more...</td>\n",
       "      <td>[inspired, human, brain, employs, neural, path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188514</th>\n",
       "      <td>1911.12784</td>\n",
       "      <td>Xueying Zhang, Wenlong Cai, Mengxing Wang, Kai...</td>\n",
       "      <td>Spin-torque memristors based on perpendicular ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[physics.app-ph]</td>\n",
       "      <td>Spin-torque memristors were proposed in 2009...</td>\n",
       "      <td>[spin, torque, memristors, proposed, could, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281705</th>\n",
       "      <td>2006.10055</td>\n",
       "      <td>Oliver H.E. Philcox, Elena Massara, and David ...</td>\n",
       "      <td>What does the Marked Power Spectrum Measure? I...</td>\n",
       "      <td>10.1103/PhysRevD.102.043516</td>\n",
       "      <td>[astro-ph.CO, astro-ph.GA, astro-ph.IM, hep-ph...</td>\n",
       "      <td>The marked power spectrum is capable of plac...</td>\n",
       "      <td>[marked, power, spectrum, capable, placing, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66392</th>\n",
       "      <td>1902.08145</td>\n",
       "      <td>Remco Duits, Etienne St-Onge, Jim Portegies, B...</td>\n",
       "      <td>Total Variation and Mean Curvature PDEs on $\\m...</td>\n",
       "      <td>None</td>\n",
       "      <td>[math.AP, math.DG]</td>\n",
       "      <td>Total variation regularization and total var...</td>\n",
       "      <td>[total, variation, regularization, total, vari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                            authors  \\\n",
       "178481  1911.02749                       Tong Zhang and Fatih Porikli   \n",
       "331163  2009.12524  Zanyar Zohourianshahzadi (UCCS) and Jugal Kuma...   \n",
       "188514  1911.12784  Xueying Zhang, Wenlong Cai, Mengxing Wang, Kai...   \n",
       "281705  2006.10055  Oliver H.E. Philcox, Elena Massara, and David ...   \n",
       "66392   1902.08145  Remco Duits, Etienne St-Onge, Jim Portegies, B...   \n",
       "\n",
       "                                                    title  \\\n",
       "178481                Sparse Coding on Cascaded Residuals   \n",
       "331163                                  Neural Twins Talk   \n",
       "188514  Spin-torque memristors based on perpendicular ...   \n",
       "281705  What does the Marked Power Spectrum Measure? I...   \n",
       "66392   Total Variation and Mean Curvature PDEs on $\\m...   \n",
       "\n",
       "                                  doi  \\\n",
       "178481                           None   \n",
       "331163  10.1109/HCCAI49649.2020.00009   \n",
       "188514                           None   \n",
       "281705    10.1103/PhysRevD.102.043516   \n",
       "66392                            None   \n",
       "\n",
       "                                                 category  \\\n",
       "178481                            [cs.CV, cs.LG, eess.IV]   \n",
       "331163                                            [cs.CV]   \n",
       "188514                                   [physics.app-ph]   \n",
       "281705  [astro-ph.CO, astro-ph.GA, astro-ph.IM, hep-ph...   \n",
       "66392                                  [math.AP, math.DG]   \n",
       "\n",
       "                                                 abstract  \\\n",
       "178481    This paper seeks to combine dictionary learn...   \n",
       "331163    Inspired by how the human brain employs more...   \n",
       "188514    Spin-torque memristors were proposed in 2009...   \n",
       "281705    The marked power spectrum is capable of plac...   \n",
       "66392     Total variation regularization and total var...   \n",
       "\n",
       "                                           clean_abstract  \n",
       "178481  [paper, seeks, combine, dictionary, learning, ...  \n",
       "331163  [inspired, human, brain, employs, neural, path...  \n",
       "188514  [spin, torque, memristors, proposed, could, pr...  \n",
       "281705  [marked, power, spectrum, capable, placing, fa...  \n",
       "66392   [total, variation, regularization, total, vari...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_1k['clean_abstract'] = docs_1k.abstract.apply(remove_punctuation).apply(lowercase).apply(remove_numbers).apply(remove_stopwords)\n",
    "docs_1k.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bd46234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>category</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178481</th>\n",
       "      <td>1911.02749</td>\n",
       "      <td>Tong Zhang and Fatih Porikli</td>\n",
       "      <td>Sparse Coding on Cascaded Residuals</td>\n",
       "      <td>None</td>\n",
       "      <td>[cs.CV, cs.LG, eess.IV]</td>\n",
       "      <td>This paper seeks to combine dictionary learn...</td>\n",
       "      <td>paper seeks combine dictionary learning hierar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331163</th>\n",
       "      <td>2009.12524</td>\n",
       "      <td>Zanyar Zohourianshahzadi (UCCS) and Jugal Kuma...</td>\n",
       "      <td>Neural Twins Talk</td>\n",
       "      <td>10.1109/HCCAI49649.2020.00009</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>Inspired by how the human brain employs more...</td>\n",
       "      <td>inspired human brain employs neural pathways i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188514</th>\n",
       "      <td>1911.12784</td>\n",
       "      <td>Xueying Zhang, Wenlong Cai, Mengxing Wang, Kai...</td>\n",
       "      <td>Spin-torque memristors based on perpendicular ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[physics.app-ph]</td>\n",
       "      <td>Spin-torque memristors were proposed in 2009...</td>\n",
       "      <td>spin torque memristors proposed could provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281705</th>\n",
       "      <td>2006.10055</td>\n",
       "      <td>Oliver H.E. Philcox, Elena Massara, and David ...</td>\n",
       "      <td>What does the Marked Power Spectrum Measure? I...</td>\n",
       "      <td>10.1103/PhysRevD.102.043516</td>\n",
       "      <td>[astro-ph.CO, astro-ph.GA, astro-ph.IM, hep-ph...</td>\n",
       "      <td>The marked power spectrum is capable of plac...</td>\n",
       "      <td>marked power spectrum capable placing far tigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66392</th>\n",
       "      <td>1902.08145</td>\n",
       "      <td>Remco Duits, Etienne St-Onge, Jim Portegies, B...</td>\n",
       "      <td>Total Variation and Mean Curvature PDEs on $\\m...</td>\n",
       "      <td>None</td>\n",
       "      <td>[math.AP, math.DG]</td>\n",
       "      <td>Total variation regularization and total var...</td>\n",
       "      <td>total variation regularization total variation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                            authors  \\\n",
       "178481  1911.02749                       Tong Zhang and Fatih Porikli   \n",
       "331163  2009.12524  Zanyar Zohourianshahzadi (UCCS) and Jugal Kuma...   \n",
       "188514  1911.12784  Xueying Zhang, Wenlong Cai, Mengxing Wang, Kai...   \n",
       "281705  2006.10055  Oliver H.E. Philcox, Elena Massara, and David ...   \n",
       "66392   1902.08145  Remco Duits, Etienne St-Onge, Jim Portegies, B...   \n",
       "\n",
       "                                                    title  \\\n",
       "178481                Sparse Coding on Cascaded Residuals   \n",
       "331163                                  Neural Twins Talk   \n",
       "188514  Spin-torque memristors based on perpendicular ...   \n",
       "281705  What does the Marked Power Spectrum Measure? I...   \n",
       "66392   Total Variation and Mean Curvature PDEs on $\\m...   \n",
       "\n",
       "                                  doi  \\\n",
       "178481                           None   \n",
       "331163  10.1109/HCCAI49649.2020.00009   \n",
       "188514                           None   \n",
       "281705    10.1103/PhysRevD.102.043516   \n",
       "66392                            None   \n",
       "\n",
       "                                                 category  \\\n",
       "178481                            [cs.CV, cs.LG, eess.IV]   \n",
       "331163                                            [cs.CV]   \n",
       "188514                                   [physics.app-ph]   \n",
       "281705  [astro-ph.CO, astro-ph.GA, astro-ph.IM, hep-ph...   \n",
       "66392                                  [math.AP, math.DG]   \n",
       "\n",
       "                                                 abstract  \\\n",
       "178481    This paper seeks to combine dictionary learn...   \n",
       "331163    Inspired by how the human brain employs more...   \n",
       "188514    Spin-torque memristors were proposed in 2009...   \n",
       "281705    The marked power spectrum is capable of plac...   \n",
       "66392     Total variation regularization and total var...   \n",
       "\n",
       "                                           clean_abstract  \n",
       "178481  paper seeks combine dictionary learning hierar...  \n",
       "331163  inspired human brain employs neural pathways i...  \n",
       "188514  spin torque memristors proposed could provide ...  \n",
       "281705  marked power spectrum capable placing far tigh...  \n",
       "66392   total variation regularization total variation...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_1k['clean_abstract'] = docs_1k['clean_abstract'].apply(lambda x:' '.join(x))\n",
    "docs_1k.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "403a6d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13278)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = docs_1k['clean_abstract']\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "X = vec.fit_transform(text)\n",
    "X = X.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a876f297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aavso</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaqus</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abcd</th>\n",
       "      <th>abelian</th>\n",
       "      <th>aberration</th>\n",
       "      <th>abilities</th>\n",
       "      <th>...</th>\n",
       "      <th>zobov</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zou</th>\n",
       "      <th>zpl</th>\n",
       "      <th>zpp</th>\n",
       "      <th>zr</th>\n",
       "      <th>zsl</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwicky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aavso   ab  abaqus  abbott  abbreviated  abcd  abelian  aberration  \\\n",
       "0  0.0    0.0  0.0     0.0     0.0          0.0   0.0      0.0         0.0   \n",
       "1  0.0    0.0  0.0     0.0     0.0          0.0   0.0      0.0         0.0   \n",
       "2  0.0    0.0  0.0     0.0     0.0          0.0   0.0      0.0         0.0   \n",
       "3  0.0    0.0  0.0     0.0     0.0          0.0   0.0      0.0         0.0   \n",
       "4  0.0    0.0  0.0     0.0     0.0          0.0   0.0      0.0         0.0   \n",
       "\n",
       "   abilities  ...  zobov  zone  zones  zou  zpl  zpp   zr  zsl  zwick  zwicky  \n",
       "0        0.0  ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0     0.0  \n",
       "1        0.0  ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0     0.0  \n",
       "2        0.0  ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0     0.0  \n",
       "3        0.0  ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0     0.0  \n",
       "4        0.0  ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 13278 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X ,columns = vec.get_feature_names_out())\n",
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
